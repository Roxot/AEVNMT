{
  "joint_model_type": "cvae",
  "num_lm_layers": 1,
  "Qx_encoder": "positional",
  "Qx_decoder": "diagonal",
  "Qx_covariance": "diagonal",
  "z_dim": 256,
  "z_inference_amortization": "full",
  "check_convergence_every": 500,
  "word_dropout": 0.0,
  "KL_annealing_steps": 0,
  "attention": "bahdanau",
  "attention_architecture": "standard",
  "batch_size": 64,
  "colocate_gradients_with_ops": true,
  "dropout": 0.3,
  "encoder_type": "bi",
  "eos": "</s>",
  "forget_bias": 1.0,
  "infer_batch_size": 64,
  "learning_rate": 0.0003,
  "max_gradient_norm": 1.0,
  "metrics": ["bleu"],
  "num_buckets": 5,
  "num_encoder_layers": 2,
  "num_decoder_layers": 1,
  "num_train_steps": 140000,
  "num_units": 256,
  "optimizer": "adam",
  "residual": false,
  "share_vocab": false,
  "subword_option": "bpe",
  "sos": "<s>",
  "src_max_len": 50,
  "src_max_len_infer": null,
  "steps_per_external_eval": 1000,
  "steps_per_stats": 100,
  "tgt_max_len": 50,
  "tgt_max_len_infer": null,
  "time_major": true,
  "unit_type": "gru",
  "beam_width": 10,
  "pass_hidden_state": false,
  "length_penalty_weight": 1.0
}
